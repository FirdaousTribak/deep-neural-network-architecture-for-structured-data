{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47816ed9-1209-4cda-9ed0-597a42fff8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21dc51d-8f65-4ec1-ae48-9e799d6634ea",
   "metadata": {},
   "source": [
    "# Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675b5c1a-bc81-4e4c-b1ef-feef0f6eac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279  ...   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225  ...   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121  ...   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211  ...   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172  ...   0   0   0   0   \n",
       "\n",
       "   49  50  51  52  53  54  \n",
       "0   0   0   0   0   0   5  \n",
       "1   0   0   0   0   0   5  \n",
       "2   0   0   0   0   0   2  \n",
       "3   0   0   0   0   0   2  \n",
       "4   0   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    ")\n",
    "raw_data = pd.read_csv(data_url, header=None)\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9dfb40e-03da-46cc-9efb-ed217e0c2e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>2596</td>\n",
       "      <td>2590</td>\n",
       "      <td>2804</td>\n",
       "      <td>2785</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>268</td>\n",
       "      <td>242</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>510</td>\n",
       "      <td>390</td>\n",
       "      <td>3180</td>\n",
       "      <td>3090</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>232</td>\n",
       "      <td>235</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>6279</td>\n",
       "      <td>6225</td>\n",
       "      <td>6121</td>\n",
       "      <td>6211</td>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type</th>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_12</td>\n",
       "      <td>soil_type_30</td>\n",
       "      <td>soil_type_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0             1             2  \\\n",
       "Elevation                                   2596          2590          2804   \n",
       "Aspect                                        51            56           139   \n",
       "Slope                                          3             2             9   \n",
       "Horizontal_Distance_To_Hydrology             258           212           268   \n",
       "Vertical_Distance_To_Hydrology                 0            -6            65   \n",
       "Horizontal_Distance_To_Roadways              510           390          3180   \n",
       "Hillshade_9am                                221           220           234   \n",
       "Hillshade_Noon                               232           235           238   \n",
       "Hillshade_3pm                                148           151           135   \n",
       "Horizontal_Distance_To_Fire_Points          6279          6225          6121   \n",
       "Wilderness_Area                      area_type_1   area_type_1   area_type_1   \n",
       "Soil_Type                           soil_type_29  soil_type_29  soil_type_12   \n",
       "Cover_Type                                     4             4             1   \n",
       "\n",
       "                                               3             4  \n",
       "Elevation                                   2785          2595  \n",
       "Aspect                                       155            45  \n",
       "Slope                                         18             2  \n",
       "Horizontal_Distance_To_Hydrology             242           153  \n",
       "Vertical_Distance_To_Hydrology               118            -1  \n",
       "Horizontal_Distance_To_Roadways             3090           391  \n",
       "Hillshade_9am                                238           220  \n",
       "Hillshade_Noon                               238           234  \n",
       "Hillshade_3pm                                122           150  \n",
       "Horizontal_Distance_To_Fire_Points          6211          6172  \n",
       "Wilderness_Area                      area_type_1   area_type_1  \n",
       "Soil_Type                           soil_type_30  soil_type_29  \n",
       "Cover_Type                                     1             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_values = [f\"soil_type_{idx+1}\" for idx in range(40)]\n",
    "wilderness_area_values = [f\"area_type_{idx+1}\" for idx in range(4)]\n",
    "\n",
    "soil_type = raw_data.loc[:, 14:53].apply(\n",
    "    lambda x: soil_type_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "wilderness_area = raw_data.loc[:, 10:13].apply(\n",
    "    lambda x: wilderness_area_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area\",\n",
    "    \"Soil_Type\",\n",
    "    \"Cover_Type\",\n",
    "]\n",
    "\n",
    "data = pd.concat(\n",
    "    [raw_data.loc[:, 0:9], wilderness_area, soil_type, raw_data.loc[:, 54]],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "data.columns = CSV_HEADER\n",
    "\n",
    "# Convert the target label indices into a range from 0 to 6 (there are 7 labels in total).\n",
    "data[\"Cover_Type\"] = data[\"Cover_Type\"] - 1\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e2371d-33d2-4988-b1a1-94a533148e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 494170\n",
      "Test split size: 86842\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in data.groupby(\"Cover_Type\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.85\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split size: {len(train_data.index)}\")\n",
    "print(f\"Test split size: {len(test_data.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027cc4fd-6e5b-46b1-8de0-5a86f277d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d331ab-8e96-44a7-a317-ba993e7c177f",
   "metadata": {},
   "source": [
    "# Define dataset metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86624ecb-788c-4097-8adb-991ea83077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = \"Cover_Type\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Aspect\",\n",
    "    \"Elevation\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Slope\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"Soil_Type\": list(data[\"Soil_Type\"].unique()),\n",
    "    \"Wilderness_Area\": list(data[\"Wilderness_Area\"].unique()),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1895e04-7330-4b03-8843-d55e35a0b5f2",
   "metadata": {},
   "source": [
    "# Experiment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e362129e-b2aa-410a-b8c7-fdb42557a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879f5f3a-49ab-4897-a0bc-b4401e2eeb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db059b41-55be-4e93-8235-d233ed9144c4",
   "metadata": {},
   "source": [
    "# Create model inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47931709-1b57-4a5f-92cb-e0ccbda9a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a459ae8-d18b-4f83-ab03-48cb1e57e0fc",
   "metadata": {},
   "source": [
    "# Encode features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3174f32-9204-4909-bad9-916c0adea1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\" if use_embedding else \"binary\",\n",
    "            )\n",
    "            if use_embedding:\n",
    "                # Convert the string input values into integer indices.\n",
    "                encoded_feature = lookup(inputs[feature_name])\n",
    "                embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "                # Create an embedding layer with the specified dimensions.\n",
    "                embedding = layers.Embedding(\n",
    "                    input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "                )\n",
    "                # Convert the index values to embedding representations.\n",
    "                encoded_feature = embedding(encoded_feature)\n",
    "            else:\n",
    "                # Convert the string input values into a one hot encoding.\n",
    "                encoded_feature = lookup(tf.expand_dims(inputs[feature_name], -1))\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256d101-860e-4c52-982a-d835e14dadc6",
   "metadata": {},
   "source": [
    "# Experiment 1: a baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c09e20-5042-43a1-9011-c69bab6349fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:2453: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67a3b1a-e862-46a9-913c-4f160aaa0c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1865/1865 [==============================] - 15s 7ms/step - loss: 0.7654 - sparse_categorical_accuracy: 0.6835\n",
      "Epoch 2/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.7146\n",
      "Epoch 3/50\n",
      "1865/1865 [==============================] - 5s 3ms/step - loss: 0.6353 - sparse_categorical_accuracy: 0.7275\n",
      "Epoch 4/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.6148 - sparse_categorical_accuracy: 0.7370\n",
      "Epoch 5/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.7403\n",
      "Epoch 6/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5961 - sparse_categorical_accuracy: 0.7443\n",
      "Epoch 7/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5919 - sparse_categorical_accuracy: 0.7464\n",
      "Epoch 8/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5869 - sparse_categorical_accuracy: 0.7482\n",
      "Epoch 9/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5829 - sparse_categorical_accuracy: 0.7502\n",
      "Epoch 10/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5796 - sparse_categorical_accuracy: 0.7522\n",
      "Epoch 11/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.7529\n",
      "Epoch 12/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5743 - sparse_categorical_accuracy: 0.7542\n",
      "Epoch 13/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5716 - sparse_categorical_accuracy: 0.7554\n",
      "Epoch 14/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.7558\n",
      "Epoch 15/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.7573\n",
      "Epoch 16/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.7580\n",
      "Epoch 17/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5629 - sparse_categorical_accuracy: 0.7589\n",
      "Epoch 18/50\n",
      "1865/1865 [==============================] - 5s 3ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7600\n",
      "Epoch 19/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.7601\n",
      "Epoch 20/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5579 - sparse_categorical_accuracy: 0.7612\n",
      "Epoch 21/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.7616\n",
      "Epoch 22/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.7623\n",
      "Epoch 23/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.7626\n",
      "Epoch 24/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5541 - sparse_categorical_accuracy: 0.7630\n",
      "Epoch 25/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.7640\n",
      "Epoch 26/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5511 - sparse_categorical_accuracy: 0.7637\n",
      "Epoch 27/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7647\n",
      "Epoch 28/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5483 - sparse_categorical_accuracy: 0.7650\n",
      "Epoch 29/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5480 - sparse_categorical_accuracy: 0.7650\n",
      "Epoch 30/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.7661\n",
      "Epoch 31/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5460 - sparse_categorical_accuracy: 0.7668\n",
      "Epoch 32/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.7672\n",
      "Epoch 33/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7676\n",
      "Epoch 34/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5427 - sparse_categorical_accuracy: 0.7680\n",
      "Epoch 35/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5429 - sparse_categorical_accuracy: 0.7676\n",
      "Epoch 36/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5422 - sparse_categorical_accuracy: 0.7686\n",
      "Epoch 37/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5420 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 38/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5416 - sparse_categorical_accuracy: 0.7694\n",
      "Epoch 39/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.7694\n",
      "Epoch 40/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7688\n",
      "Epoch 41/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7699\n",
      "Epoch 42/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.7704\n",
      "Epoch 43/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5374 - sparse_categorical_accuracy: 0.7710\n",
      "Epoch 44/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 45/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.7710\n",
      "Epoch 46/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.7703\n",
      "Epoch 47/50\n",
      "1865/1865 [==============================] - 7s 3ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 48/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5361 - sparse_categorical_accuracy: 0.7711\n",
      "Epoch 49/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5363 - sparse_categorical_accuracy: 0.7713\n",
      "Epoch 50/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5354 - sparse_categorical_accuracy: 0.7715\n",
      "Model training finished\n",
      "Test accuracy: 75.05%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea882f4e-ba52-40a9-9c3e-f625a9739e11",
   "metadata": {},
   "source": [
    "# Experiment 2: Wide & Deep model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89ef74a3-f52c-41c4-bd1d-821bd56276f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af3701eb-77ee-4558-b133-dc3befba87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1865/1865 [==============================] - 12s 6ms/step - loss: 0.7100 - sparse_categorical_accuracy: 0.7061\n",
      "Epoch 2/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.6032 - sparse_categorical_accuracy: 0.7372\n",
      "Epoch 3/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.7451\n",
      "Epoch 4/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.7514\n",
      "Epoch 5/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.7550\n",
      "Epoch 6/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.7574\n",
      "Epoch 7/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.7601\n",
      "Epoch 8/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7623\n",
      "Epoch 9/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.7642\n",
      "Epoch 10/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5388 - sparse_categorical_accuracy: 0.7663\n",
      "Epoch 11/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5351 - sparse_categorical_accuracy: 0.7677\n",
      "Epoch 12/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7691\n",
      "Epoch 13/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.7706\n",
      "Epoch 14/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5261 - sparse_categorical_accuracy: 0.7722\n",
      "Epoch 15/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5244 - sparse_categorical_accuracy: 0.7733\n",
      "Epoch 16/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5226 - sparse_categorical_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5208 - sparse_categorical_accuracy: 0.7755\n",
      "Epoch 18/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5181 - sparse_categorical_accuracy: 0.7770\n",
      "Epoch 19/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.7776\n",
      "Epoch 20/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5171 - sparse_categorical_accuracy: 0.7772\n",
      "Epoch 21/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5150 - sparse_categorical_accuracy: 0.7790\n",
      "Epoch 22/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5146 - sparse_categorical_accuracy: 0.7788\n",
      "Epoch 23/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.7789\n",
      "Epoch 24/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.7798\n",
      "Epoch 25/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5119 - sparse_categorical_accuracy: 0.7803\n",
      "Epoch 26/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5114 - sparse_categorical_accuracy: 0.7806\n",
      "Epoch 27/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5101 - sparse_categorical_accuracy: 0.7810\n",
      "Epoch 28/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5097 - sparse_categorical_accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5087 - sparse_categorical_accuracy: 0.7816\n",
      "Epoch 30/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5076 - sparse_categorical_accuracy: 0.7822\n",
      "Epoch 31/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.7822\n",
      "Epoch 32/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5064 - sparse_categorical_accuracy: 0.7827\n",
      "Epoch 33/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.7826\n",
      "Epoch 34/50\n",
      "1865/1865 [==============================] - 7s 3ms/step - loss: 0.5061 - sparse_categorical_accuracy: 0.7830\n",
      "Epoch 35/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 36/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5048 - sparse_categorical_accuracy: 0.7835\n",
      "Epoch 37/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5040 - sparse_categorical_accuracy: 0.7841\n",
      "Epoch 38/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.7847\n",
      "Epoch 39/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5034 - sparse_categorical_accuracy: 0.7848\n",
      "Epoch 40/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5027 - sparse_categorical_accuracy: 0.7849\n",
      "Epoch 41/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5022 - sparse_categorical_accuracy: 0.7852\n",
      "Epoch 42/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.7853\n",
      "Epoch 43/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5015 - sparse_categorical_accuracy: 0.7856\n",
      "Epoch 44/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5002 - sparse_categorical_accuracy: 0.7863\n",
      "Epoch 45/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4993 - sparse_categorical_accuracy: 0.7864\n",
      "Epoch 46/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4988 - sparse_categorical_accuracy: 0.7858\n",
      "Epoch 47/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7872\n",
      "Epoch 48/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4985 - sparse_categorical_accuracy: 0.7870\n",
      "Epoch 49/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.7870\n",
      "Epoch 50/50\n",
      "1865/1865 [==============================] - 7s 3ms/step - loss: 0.4973 - sparse_categorical_accuracy: 0.7880\n",
      "Model training finished\n",
      "Test accuracy: 80.29%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(wide_and_deep_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c28d5-7ca2-4df3-8d83-f7bcd3e87fe1",
   "metadata": {},
   "source": [
    "# Experiment 3: Deep & Cross model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d6b332-f1ac-49c4-83d1-8f2331948907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_deep_and_cross_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    x0 = encode_inputs(inputs, use_embedding=True)\n",
    "\n",
    "    cross = x0\n",
    "    for _ in hidden_units:\n",
    "        units = cross.shape[-1]\n",
    "        x = layers.Dense(units)(cross)\n",
    "        cross = x0 * x + cross\n",
    "    cross = layers.BatchNormalization()(cross)\n",
    "\n",
    "    deep = x0\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([cross, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "deep_and_cross_model = create_deep_and_cross_model()\n",
    "keras.utils.plot_model(deep_and_cross_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b859d03-2419-4e8b-b61b-3644fd49964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1865/1865 [==============================] - 14s 6ms/step - loss: 0.6995 - sparse_categorical_accuracy: 0.7087\n",
      "Epoch 2/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.7460\n",
      "Epoch 3/50\n",
      "1865/1865 [==============================] - 7s 3ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7542\n",
      "Epoch 4/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5616 - sparse_categorical_accuracy: 0.7593\n",
      "Epoch 5/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.7629\n",
      "Epoch 6/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5481 - sparse_categorical_accuracy: 0.7646\n",
      "Epoch 7/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.7670\n",
      "Epoch 8/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5393 - sparse_categorical_accuracy: 0.7687\n",
      "Epoch 9/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7704\n",
      "Epoch 10/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7710\n",
      "Epoch 11/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.7725\n",
      "Epoch 12/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5273 - sparse_categorical_accuracy: 0.7734\n",
      "Epoch 13/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5249 - sparse_categorical_accuracy: 0.7748\n",
      "Epoch 14/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5225 - sparse_categorical_accuracy: 0.7760\n",
      "Epoch 15/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5203 - sparse_categorical_accuracy: 0.7768\n",
      "Epoch 16/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5185 - sparse_categorical_accuracy: 0.7781\n",
      "Epoch 17/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5157 - sparse_categorical_accuracy: 0.7783\n",
      "Epoch 18/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.5139 - sparse_categorical_accuracy: 0.7793\n",
      "Epoch 19/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5115 - sparse_categorical_accuracy: 0.7807\n",
      "Epoch 20/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5104 - sparse_categorical_accuracy: 0.7815\n",
      "Epoch 21/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.7820\n",
      "Epoch 22/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.7821\n",
      "Epoch 23/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5056 - sparse_categorical_accuracy: 0.7828\n",
      "Epoch 24/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5046 - sparse_categorical_accuracy: 0.7835\n",
      "Epoch 25/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5033 - sparse_categorical_accuracy: 0.7843\n",
      "Epoch 26/50\n",
      "1865/1865 [==============================] - 10s 5ms/step - loss: 0.5023 - sparse_categorical_accuracy: 0.7845\n",
      "Epoch 27/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5014 - sparse_categorical_accuracy: 0.7841\n",
      "Epoch 28/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4991 - sparse_categorical_accuracy: 0.7851\n",
      "Epoch 29/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7856\n",
      "Epoch 30/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4962 - sparse_categorical_accuracy: 0.7862\n",
      "Epoch 31/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4955 - sparse_categorical_accuracy: 0.7866\n",
      "Epoch 32/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4941 - sparse_categorical_accuracy: 0.7875\n",
      "Epoch 33/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7872\n",
      "Epoch 34/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.7884\n",
      "Epoch 35/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4910 - sparse_categorical_accuracy: 0.7885\n",
      "Epoch 36/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4900 - sparse_categorical_accuracy: 0.7896\n",
      "Epoch 37/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4894 - sparse_categorical_accuracy: 0.7894\n",
      "Epoch 38/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4881 - sparse_categorical_accuracy: 0.7899\n",
      "Epoch 39/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4867 - sparse_categorical_accuracy: 0.7902\n",
      "Epoch 40/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4857 - sparse_categorical_accuracy: 0.7906\n",
      "Epoch 41/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4850 - sparse_categorical_accuracy: 0.7914\n",
      "Epoch 42/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4838 - sparse_categorical_accuracy: 0.7922\n",
      "Epoch 43/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4830 - sparse_categorical_accuracy: 0.7924\n",
      "Epoch 44/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4825 - sparse_categorical_accuracy: 0.7925\n",
      "Epoch 45/50\n",
      "1865/1865 [==============================] - 10s 5ms/step - loss: 0.4819 - sparse_categorical_accuracy: 0.7925\n",
      "Epoch 46/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4817 - sparse_categorical_accuracy: 0.7929\n",
      "Epoch 47/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4800 - sparse_categorical_accuracy: 0.7935\n",
      "Epoch 48/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4799 - sparse_categorical_accuracy: 0.7938\n",
      "Epoch 49/50\n",
      "1865/1865 [==============================] - 6s 3ms/step - loss: 0.4785 - sparse_categorical_accuracy: 0.7947\n",
      "Epoch 50/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.4786 - sparse_categorical_accuracy: 0.7945\n",
      "Model training finished\n",
      "Test accuracy: 80.17%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(deep_and_cross_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef38046-2944-4cce-a10a-a461bf8b6887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
